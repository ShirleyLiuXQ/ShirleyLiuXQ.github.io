<h1 style="font-size:30px">Research</h1>

My research focuses on **<span style="color:darkred">machine learning theory</span>** in the presence of data heterogeneity. Given the abundance of empirical advances in machine learning and the relative scarcity of theoretical foundations, I believe understanding the fundamental limits in estimation and learning problems is crucial for developing more efficient and principled systems. I am particularly interested in investigating such theoretical groundings under **<span style="color:darkred">data heterogeneity</span>**, as real-world datasets often vary across geographic locations, time periods, and user populations. For example, I study the fundamental tradeoff between sample complexity and estimation error in changepoint detection, and I characterize the minimum regret achievable in non-stationary convex bandits.

During my PhD, I focused extensively on **<span style="color:darkred">message passing algorithms</span>** for statistical estimation: a class of computationally efficient, iterative methods that can achieve statistical optimality across various problems. I studied both belief propagation and [approximate message passing (AMP)](https://ieeexplore.ieee.org/document/9785928).

## Interests:
- Data heterogeneity: non-stationarity, adversarial contamination, and distribution shifts
- Online learning, bandits
- Uncertainty quantification, algorithmic statistics
- General first-order methods, e.g., gradient descent, approximate message passing
- Information theory and communication systems

## Preprints:
**X. Liu**, D. Baudry, J. Zimmert, P. Rebeschini, A. Akhavan, "[Non-stationary Bandit Convex Optimization: A Comprehensive Study](https://arxiv.org/abs/2506.02980)", to appear in *Proceedings of the 39th Annual Conference on Neural Information Processing Systems*, 2025. ([poster](neurips_poster_bandits.pdf), [talk](CDT_bandits_talk(20mins).pdf))


J. Allison, P. Anderson, E. Aranas, Y. Assaf, M. Caballero, J. Chattaway, A Chatzieleftheriou, J. Clegg, B. Cooper, T. Deegan, A. Donnelly, R. Drevinskas, C. Gkantsidis, A. G. Diaz, I. Haller, F. Hong, T. Ilieva, R. Joyce, V. Kapitany, W. Kunkel, D. Lara, T. Lawson, S. Legtchenko, F. Liu, **X. Liu**, B. Magalhaes, S. Nowozin, H. Overweg, A. Rowstron, M. Sakakura, N. Schreiner, A. Smith, O. Snowdon, I. Stefanovici, D. Sweeney, G. Verkes, P. Wainman, C. Whittaker, P. W. Berenguer, H. Williams, T. Winkler, S. Winzeck, R. Black, B. Canakci, D. Cletheroe, Z. Feng, "Laser writing in glass for dense, fast and efficient archival data storage", to appear in <span style="color:#007BFF">*Nature*</span>, 2025.

**X. Liu**, P. Pascual Cobo and R. Venkataramanan, "[Many-user multiple access with random user activity: achievability bounds and efficient schemes](https://arxiv.org/abs/2412.01511)", to appear in *IEEE Transactions on Information Theory*, 2025, doi: 10.1109/TIT.2025.3622969.

G. Arpino, **X. Liu**, J. Gontarek and R. Venkataramanan, "[Inferring Change Points in High-Dimensional Regression via Approximate Message Passing](https://arxiv.org/abs/2404.07864)", to appear in *Journal of Machine Learning Research*, 2025.

**X. Liu**, K. Hsieh and R. Venkataramanan, "[Coded many-user multiple access via Approximate Messsage Passing](https://arxiv.org/abs/2402.05625)", to appear in *Information Theory, Probability and Statistical Learning: A Festschrift in Honor of Andrew Barron*, 2025.

## Publications:
**X. Liu**, P. Pascual Cobo and R. Venkataramanan, "[Many-user multiple access with random user activity](https://ieeexplore.ieee.org/abstract/document/10619669)", *IEEE International Symposium on Information Theory*, Athens, Greece, 2024. ([poster](ESIT_GMAC_poster_final.pdf), [talk](RA_isit2024(17mins).pdf))

**X. Liu**, K. Hsieh and R. Venkataramanan, "[Coded many-user multiple access via Approximate Messsage Passing](https://ieeexplore.ieee.org/abstract/document/10619478)", *IEEE International Symposium on Information Theory*, Athens, Greece, 2024. ([talk](CDMA_isit2024(17mins).pdf))

G. Arpino, **X. Liu** and R. Venkataramanan, "[Inferring Change Points in High-Dimensional Linear Regression via Approximate Message Passing](https://proceedings.mlr.press/v235/arpino24a.html)", *Proceedings of the 41st International Conference on Machine Learning*, PMLR 235:1841-1864, 2024. ([poster](changepoints_poster.pdf), [code](https://github.com/gabrielarpino/AMP_chgpt_lin_reg))

**X. Liu** and R. Venkataramanan, "[Sketching Sparse Low-Rank Matrices With Near-Optimal Sample- and Time-Complexity Using Message Passing](https://ieeexplore.ieee.org/document/10120641)", in *IEEE Transactions on Information Theory*, vol. 69, no. 9, pp. 6071-6097, Sept. 2023, doi: 10.1109/TIT.2023.3273181.

**X. Liu** and R. Venkataramanan, "[Sketching sparse low-rank matrices with near-optimal sample- and time-complexity](https://ieeexplore.ieee.org/document/9834693)", *IEEE International Symposium on Information Theory*, Espoo, Finland, 2022, pp. 3138-3143, doi: 10.1109/ISIT50566.2022.9834693. (<a href="/ISIT_talk_Shirley_Liu_website_version.pdf">talk</a>) 

## PhD thesis:
**X. Liu**, "[Message Passing Algorithms for Statistical Estimation and Communication](https://doi.org/10.17863/CAM.112616)", Apollo-University of Cambridge Repository.

## Service:
I review papers for several conferences and journals including the Conference on Neural Information Processing Systems (NeurIPS) (top reviewer 2024), International Conference on Machine Learning (ICML), Transactions on Machine Learning Research, and International Symposium on Information Theory (ISIT).

## Notes:
Here are some recent tutorial slides I made on e-values and e-processes primarily based on the [textbook by Ramdas and Wang](https://arxiv.org/abs/2410.23614): [talk1](Ramdas_Wang_ebook_chapter7-2.pdf), [talk2](SAVI_tutorial_shirley.pdf)